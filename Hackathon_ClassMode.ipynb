{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preload libraries and functions\n",
    "First of all, let's import libraries that will be used in this example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T09:07:13.729285Z",
     "start_time": "2018-11-27T09:07:13.584787Z"
    }
   },
   "outputs": [],
   "source": [
    "# clear all variants\n",
    "%reset -f   \n",
    "\n",
    "# Autoreload the customize modules.\n",
    "%reload_ext autoreload\n",
    "# Or load_ext autoreload for the first run\n",
    "%aimport HackModules.HackClasses, HackModules.HackFunctions \n",
    "%autoreload 1\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing as prep\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import tensorflow as tf\n",
    "# from tensorflow import keras\n",
    "\n",
    "import HackModules.HackClasses as hc\n",
    "import HackModules.HackFunctions as hf\n",
    "\n",
    "#matplot inline\n",
    "# np.set_printoptions(precision=8)\n",
    "\n",
    "# help(hc) # To test the docstrings ((TBDBS To be deleted before submission))\n",
    "\n",
    "# Alternative customize module import method\n",
    "# import sys, os\n",
    "# sys.path.append(os.getcwd()+'/HackModules/') # add /HackModules to the path\n",
    "# import HackClasses as hc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define some seldom used functions and class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-27T08:55:14.712325Z",
     "start_time": "2018-11-27T08:55:14.704272Z"
    }
   },
   "outputs": [],
   "source": [
    "%reset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Import and Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('obs_data_w.xlsx', sheet_name=0) #sheet_name='Sheet1')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train, cross validation and test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Method 1: Sample function of df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=df.sample(frac=0.8) # randaom_state=200\n",
    "test=df.drop(temp.index)\n",
    "test=test.sample(frac=1) # shuffle the rows\n",
    "train=temp.sample(frac=0.75)\n",
    "cv=temp.drop(train.index)\n",
    "print(train.shape)\n",
    "print(cv.shape)\n",
    "print(test.shape)\n",
    "# train=data(train)\n",
    "# cv=data(cv)\n",
    "# test=data(test)\n",
    "# print(train.array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Random Method 2: random array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# idx=np.arange(0,len(df))\n",
    "# np.random.shuffle(idx)\n",
    "# temp_split=math.floor(0.8*len(df))\n",
    "# #idx[0:20]\n",
    "# train=df.iloc[idx[0:temp_split],:]\n",
    "# test=df.iloc[idx[temp_split:],:] # Output all the elements after temp_split\n",
    "# print(train.shape)\n",
    "# print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the data into data and results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=train.loc[:,['V','T']]\n",
    "train_unc=train.uncertainty.values\n",
    "train_J=train.J.values\n",
    "\n",
    "cv_data=cv.loc[:,['V','T']]\n",
    "cv_unc=cv.uncertainty.values\n",
    "cv_J=cv.J.values\n",
    "\n",
    "test_data=test.loc[:,['V','T']]\n",
    "test_unc=test.uncertainty.values\n",
    "test_J=test.J.values\n",
    "\n",
    "train=data(train_data)\n",
    "cv=data(cv_data)\n",
    "test=data(test_data)\n",
    "\n",
    "# print(test_data)\n",
    "# J=J.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add the polynominal features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train data\n",
    "train_data_poly = train.polyFeature(2)\n",
    "print('train_data = \\n', train_data_poly, '\\n')  # print(f'train_data=\\n{train_data_array}')\n",
    "\n",
    "# cv data\n",
    "cv_data_poly=cv.polyFeature(2)\n",
    "print('cross validation = \\n', cv_data_poly, '\\n')\n",
    "\n",
    "# test data\n",
    "test_data_poly=test.polyFeature(2)\n",
    "print('test data = \\n', test_data_poly, '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Normalization (Two methods, range or stand deviation)  \n",
    "\n",
    "(__We should try both__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization method\n",
    "method='std'\n",
    "\n",
    "# # train data\n",
    "# train_data_norm=normalizeFeature(train_data_poly, method)\n",
    "# print('normalized train_data = \\n', train_data_norm, '\\n')\n",
    "\n",
    "# # cross valiation data\n",
    "# cv_data_norm=normalizeFeature(cv_data_poly, method)\n",
    "# print('normalized cv_data = \\n', cv_data_norm, '\\n')\n",
    "\n",
    "# # test data\n",
    "# test_data_norm=normalizeFeature(test_data_poly, method)\n",
    "# print('normalized test_data = \\n', test_data_norm, '\\n')\n",
    "\n",
    "#\n",
    "# train_data_norm_class=train.polyFeature(3)\n",
    "train_data_norm_class=train.normalizeFeature('std')\n",
    "print(train_data_norm_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 1: Normal Equation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Training without regulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "theta=normalEq(train_data_norm, train_J) \n",
    "print(f'theta = {theta}')\n",
    "error_train=computeCost(train_data_norm, train_J, theta)\n",
    "error_test=computeCost(test_data_norm, test_J, theta)\n",
    "\n",
    "print('The training error is ', error_train)\n",
    "print('The test error is ', error_test)\n",
    "\n",
    "# OTHER PRINT EXPRESSION WITH FORMAT\n",
    "# print('The training error is %.10f'%error)\n",
    "# print('error = {:.10f}'.format(error))\n",
    "# print(f'error = {error}')\n",
    "# print('error= ', error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training with regulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "featureSize=train_data_norm.shape[1]\n",
    "beta_range=np.geomspace(0.001,50, num = 200, endpoint = True, dtype=np.float64)\n",
    "beta_range=np.insert(beta_range,0,0) # insert a zero element in the first index\n",
    "theta_reg=np.zeros((beta_range.size, featureSize))\n",
    "error_train_reg=np.zeros(beta_range.size)\n",
    "error_cv_reg=np.zeros(beta_range.size)\n",
    "for index, beta in enumerate(beta_range):\n",
    "    theta_reg[index]=normalRegEq(train_data_norm, train_J, beta)\n",
    "    error_train_reg[index]=computeCost(train_data_norm, train_J, theta_reg[index])\n",
    "    error_cv_reg[index]=computeCost(cv_data_norm, cv_J, theta_reg[index])\n",
    "\n",
    "# plot error vs. beta\n",
    "plt.figure()\n",
    "plt.plot(beta_range, error_cv_reg, label = 'Val error')\n",
    "plt.plot(beta_range, error_train_reg, label = 'Train error')\n",
    "plt.xlabel('regulization coefficient (beta)')\n",
    "plt.ylabel('error')\n",
    "plt.legend()\n",
    "\n",
    "idx=error_cv_reg.argmin()\n",
    "beta_best = beta_range[idx]\n",
    "theta_best = theta_reg[idx]\n",
    "error_test_reg=computeCost(test_data_norm, test_J, theta_best)\n",
    "\n",
    "print('The best value of THETA is ', theta_best)\n",
    "print('The best value of BETA is ', beta_best)\n",
    "print('The test error is ', error_test_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=data(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(t.array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.polyFeature(2)\n",
    "t.array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(theta_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:NUSworkshop]",
   "language": "python",
   "name": "conda-env-NUSworkshop-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
